{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8c8a6-3a61-4419-ae17-768a061f00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from tkinter import filedialog\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c7675-8271-432c-bdd6-3dabf7cef5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated folder structure mapping\n",
    "LABELS = {\n",
    "    'in-range-light': 1,\n",
    "    'in-range-dark': 1,\n",
    "    'in-range-normal': 1,\n",
    "    'out-of-range-too-light': 0,\n",
    "    'out-of-range-too-dark': 0,\n",
    "    'out_range': 0\n",
    "}\n",
    "\n",
    "# Function to apply Lab conversion and CLAHE\n",
    "def extract_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
    "    \n",
    "    # Extract statistical features\n",
    "    l_mean, a_mean, b_mean = lab[:,:,0].mean(), lab[:,:,1].mean(), lab[:,:,2].mean()\n",
    "    l_std, a_std, b_std = lab[:,:,0].std(), lab[:,:,1].std(), lab[:,:,2].std()\n",
    "    \n",
    "    return [l_mean, a_mean, b_mean, l_std, a_std, b_std]\n",
    "\n",
    "# Load dataset based on new folder structure\n",
    "def load_dataset(base_dir='images'):\n",
    "    X, y = [], []\n",
    "    for folder, label in LABELS.items():\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: Missing folder {folder_path}\")\n",
    "            continue\n",
    "        for file in tqdm(os.listdir(folder_path), desc=f\"Loading {folder}\"):\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            features = extract_features(img_path)\n",
    "            if features:\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5ec8c-ea94-4f60-a5b8-7749ae41d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "X, y = load_dataset()\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train multiple models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM (RBF Kernel)\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"MLP Neural Network\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2052a19-530e-46a0-84ee-7413503e5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate and store performance\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    model_performance[name] = acc\n",
    "    print(f\"{name} Accuracy: {acc*100:.2f}%\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(model, f\"{name.replace(' ', '_')}_model.pkl\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'graphite_walnut_scaler.pkl')\n",
    "\n",
    "# Display model performance comparison\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "for name, acc in model_performance.items():\n",
    "    print(f\"{name}: {acc*100:.2f}%\")\n",
    "\n",
    "print(\"Models and scaler saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414519b2-1e3f-485b-a1a6-dad716c325b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image():\n",
    "    \"\"\" Open file dialog for image upload \"\"\"\n",
    "    file_path = filedialog.askopenfilename(title=\"Select Image\", filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    return file_path\n",
    "\n",
    "def validate_sample(model_name):\n",
    "    print(f\"\\nUsing {model_name} model for validation...\")\n",
    "    print(\"Upload the known in-range sample:\")\n",
    "    ref_path = upload_image()\n",
    "    ref_features = extract_features(ref_path)\n",
    "    if ref_features is None:\n",
    "        print(\"Invalid reference image. Please try again.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Upload the sample to be validated:\")\n",
    "    sample_path = upload_image()\n",
    "    sample_features = extract_features(sample_path)\n",
    "    if sample_features is None:\n",
    "        print(\"Invalid sample image. Please try again.\")\n",
    "        return\n",
    "    \n",
    "    # Normalize features relative to reference sample\n",
    "    scaler = joblib.load('graphite_walnut_scaler.pkl')\n",
    "    model = joblib.load(f\"{model_name.replace(' ', '_')}_model.pkl\")\n",
    "    \n",
    "    # Compute relative features\n",
    "    normalized_sample = np.array(sample_features) - np.array(ref_features)\n",
    "    normalized_sample = scaler.transform([normalized_sample])\n",
    "    \n",
    "    prediction = model.predict(normalized_sample)[0]\n",
    "    result = \"In Range\" if prediction == 1 else \"Out of Range\"\n",
    "    \n",
    "    print(f\"Sample Validation Result: {result}\")\n",
    "\n",
    "# Choose model for validation\n",
    "print(\"\\nSelect the model you want to use for validation:\")\n",
    "for i, name in enumerate(models.keys()):\n",
    "    print(f\"{i+1}. {name}\")\n",
    "\n",
    "choice = int(input(\"Enter the number corresponding to the model: \")) - 1\n",
    "selected_model = list(models.keys())[choice]\n",
    "\n",
    "# Run validation with the selected model\n",
    "validate_sample(selected_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
