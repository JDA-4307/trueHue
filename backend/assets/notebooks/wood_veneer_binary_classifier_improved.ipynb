{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b235b141",
   "metadata": {},
   "source": [
    "# Improved Wood Veneer Binary Classifier (Transfer Learning & TFLite)\n",
    "This notebook trains a robust binary classifier for a selected wood stain color using advanced techniques:\n",
    "- **Transfer Learning** with a pre-trained backbone (e.g., EfficientNetB0)\n",
    "- **Data Augmentation** via Keras preprocessing layers\n",
    "- **Class Weights** to handle imbalance or **Focal Loss**\n",
    "- **Learning-Rate Scheduling** and **Fine-Tuning**\n",
    "- **TFLite Conversion** for deployment on edge devices\n",
    "\n",
    "Set your parameters in the configuration cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e79a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "# Stain color: 'medium-cherry', 'desert-oak', or 'graphite-walnut'\n",
    "COLOR_NAME = 'medium-cherry'\n",
    "\n",
    "# Dataset root directory\n",
    "ROOT_DIR = '/Users/rishimanimaran/Documents/College/junior-year/spring-2025/cs-3312/color-validation-app-spring/images-dataset-5.0'\n",
    "\n",
    "# Backbone choice: 'EfficientNetB0' or 'ResNet50V2'\n",
    "BACKBONE = 'EfficientNetB0'\n",
    "\n",
    "# Image & training parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCHS = 5     # Train top head\n",
    "FINE_TUNE_EPOCHS = 10  # After unfreezing\n",
    "UNFREEZE_LAYERS = 20   # Number of layers from backbone to unfreeze\n",
    "\n",
    "# Learning rates\n",
    "LR_HEAD = 1e-3\n",
    "LR_FINE = 1e-5\n",
    "\n",
    "# Use focal loss instead of binary_crossentropy?\n",
    "USE_FOCAL_LOSS = True\n",
    "\n",
    "# Convert to TFLite at end?\n",
    "EXPORT_TFLITE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d995ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtfa\u001b[39;00m  \u001b[38;5;66;03m# for focal loss\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m class_weight\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Dataset directory for selected color\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "## Imports & Setup\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa  # for focal loss\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Dataset directory for selected color\n",
    "dataset_dir = os.path.join(ROOT_DIR, COLOR_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad70589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Datasets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred', label_mode='binary',\n",
    "    batch_size=BATCH_SIZE, image_size=IMG_SIZE,\n",
    "    validation_split=0.2, subset='training', seed=42\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred', label_mode='binary',\n",
    "    batch_size=BATCH_SIZE, image_size=IMG_SIZE,\n",
    "    validation_split=0.2, subset='validation', seed=42\n",
    ")\n",
    "# Prefetch\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Compute class weights\n",
    "y_train = np.concatenate([y.numpy() for x, y in train_ds], axis=0)\n",
    "weights = class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train), y=y_train\n",
    ")\n",
    "class_weights = {i: w for i, w in enumerate(weights)}\n",
    "print('Class weights:', class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.1),\n",
    "    \n",
    "], name='data_augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Model Function\n",
    "def build_model(backbone_name):\n",
    "    # Input\n",
    "    inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "    # Augmentation & normalization\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Rescaling(1./255)(x)\n",
    "    # Backbone\n",
    "    if backbone_name == 'EfficientNetB0':\n",
    "        base = keras.applications.EfficientNetB0(\n",
    "            include_top=False, weights='imagenet', input_tensor=x\n",
    "        )\n",
    "    else:\n",
    "        base = keras.applications.ResNet50V2(\n",
    "            include_top=False, weights='imagenet', input_tensor=x\n",
    "        )\n",
    "    base.trainable = False\n",
    "    # Head\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c31067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate & Compile Model (Head Training)\n",
    "model = build_model(BACKBONE)\n",
    "loss_fn = (\n",
    "    tfa.losses.SigmoidFocalCrossEntropy() if USE_FOCAL_LOSS\n",
    "    else 'binary_crossentropy'\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LR_HEAD),\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41473797",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_head.h5', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c635939",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Top Head\n",
    "history_head = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=INITIAL_EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fine-Tuning: Unfreeze Last Layers\n",
    "# Unfreeze last UNFREEZE_LAYERS of the backbone\n",
    "base_model = model.layers[3]  # data_augmentation, rescaling, then base at index 3\n",
    "for layer in base_model.layers[-UNFREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "print(f'Unfroze {UNFREEZE_LAYERS} layers of the backbone.')\n",
    "\n",
    "# Recompile with lower LR & schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    initial_learning_rate=LR_FINE,\n",
    "    first_decay_steps=FINE_TUNE_EPOCHS\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fine-Tune Model\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate on Validation Set\n",
    "loss, acc = model.evaluate(val_ds)\n",
    "print(f'Validation Loss: {loss:.4f}, Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert & Save TFLite Model\n",
    "if EXPORT_TFLITE:\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    fname = f'{COLOR_NAME}_improved_classifier.tflite'\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f'TFLite model saved to {fname}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apple_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
